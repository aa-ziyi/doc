# 1、提高页面加载速度。 
能用css解决的不用背景图片，背景图片也尽量压缩大小，可以几个icons放在一个图片上，采用css精灵(css sprite)，使用background-position找到需要的图片位置。减少HTTP请求数，提高网页加载速度。 
# 2、结构、表现和行为的分离。
另外一个重要的拖慢网页加载速度的原因就是将css和JS都堆积在HTML页面上，每次看到有人直接在页面上编写CSS和JS我都很痛心疾首。通过外链的方式能大大加快网页加载速度的，css文件可以放在head里，JS文件可以放置在body的最下方，在不影响阅读的情况下再去加载JS文件。 

# 3、优化网站分级结构。
在每个内页加面包屑导航是很有必要的，可以让蜘蛛进入页面之后不至于迷路，有条件的话，最好能单独加个Sitemap页面，将网站结构一目了然地展示在蜘蛛面前，更有利于蜘蛛抓取信息。 

# 4、集中网站权重。
由于蜘蛛分配到每个页面的权重是一定的，这些权重也将平均分配到每个a链接上，那么为了集中网站权重，可以使用”rel=nofollow”属性，它告诉蜘蛛无需抓取目标页,可以将权重分给其他的链接。 

# 5、文本强调标签的使用。
当着重强调某个关键词需要加粗表示，选用strong标签比使用b标签要更有强调作用。

# 6、 a标签的title属性的使用。
在不影响页面功能的情况下，可以尽量给a标签加上title属性，可以更有利于蜘蛛抓取信息。

# 7、 图片alt属性的使用。
这个属性可以在图片加载不出来的时候显示在页面上相关的文字信息，作用同上。 

# 8、 H标签的使用。
主要是H1标签的使用需要特别注意，因为它自带权重，一个页面有且最多只能有一个H1标签，放在该页面最重要的标题上面，如首页的logo上可以加H1标签。 

# 9、图片大小声明。
如果图片大小不做定义的话，页面需要重新渲染，就会影响到加载速度。 

# 10\页面布局调整。
页面内容尽量不要做成flash、视频，这些东西蜘蛛是抓不到的，就算是必须的，也要生成相应的静态页面。 

# 11、网站结构呈扁平状树型，
目录结构不宜过深。每个页面离首页最多点击不超过3次，过深不利于搜索引擎的抓取。


# seo实战
seo本身涉及范围非常广，所包含的知识也是非常值得深入研究的一个方向，本文仅从重构侧出发聊聊最近做的一些。

## TDK优化
TDK为title,description,keywords三个的统称。当然title是最有用的，是非常值得优化的；而keywords因为以前被seo人员过度使用，所以现在对这个进行优化对搜索引擎是没用的，这里就不说了；description的描述会直接显示在搜索的介绍中，所以对用户的判断是否点击还是非常有效的。

## title优化
title的分隔符一般有,,_,-等，其中_对百度比较友好，而-对谷歌比较友好，第四个为空格，英文站点可以使用，中文少用。title长度一般pc端大概30个中文，移动端20个，超过则会截断为省略号。
因为业务关系，我们做的更多的是针对百度搜索引擎的优化，所以这里把百度搜索引擎优化的建议分享下：
title格式：
首页：网站名称 或者 网站名称_提供服务介绍or产品介绍
频道页：频道名称_网站名称
文章页：文章title_频道名称_网站名称
如果你的文章标题不是很长，还可以加入点关键词进去，如文章title_关键词_网站名称
推荐做法：
每个网页应该有一个独一无二的标题，切忌所有的页面都使用同样的默认标题
标题要主题明确，包含这个网页中最重要的内容
简明精练，不罗列与网页内容不相关的信息
用户浏览通常是从左到右的，重要的内容应该放到title的靠前的位置
使用用户所熟知的语言描述。如果你有中、英文两种网站名称，尽量使用用户熟知的那一种做为标题描述

## description优化
description不是权值计算的参考因素，这个标签存在与否不影响网页权值，只会用做搜索结果摘要的一个选择目标。其长度pc端大概为78个中文，移动端为50个，超过则会截断为省略号。
百度推荐做法为：
网站首页、频道页、产品参数页等没有大段文字可以用做摘要的网页最适合使用description
准确的描述网页，不要堆砌关键词
为每个网页创建不同的description，避免所有网页都使用同样的描述
长度合理，不过长不过短
下面以百度推荐的两个例子为对比，第一个没有应用meta description，第二个应用了meta description，可以看出第一个结果的摘要对用户基本没有参考价值，第二个结果的摘要更具可读性，可以让用户更了解网站的内容。
seo优化 description优化

## 页面内容优化
使用html5结构
如果条件允许（如移动端，兼容ie9+，如果ie8+就针对ie8引入html5.js吧），是时候开始考虑使用html5语义化标签。如header,footer,section,aside,nav,article等，这里我们截图看一个整体布局
seo优化，html5结构
更多html5语义化标签请参考：All HTML5 Tags

## 唯一的H1标题
每个页面都应该有个唯一的h1标题，但不是每个页面的h1标题都是站点名称。（但html5中h1标题是可以多次出现的，每个具有结构大纲的标签都可以拥有自己独立的h1标题，如header,footer,section,aside,article）
首页的h1标题为站点名称，内页的h1标题为各个内页的标题，如分类页用分类的名字，详细页用详细页标题作为h1标题
```html
<!-- 首页 -->
<h1 class="page-tt">腾讯课堂</h1>
<!-- 分类页 -->
<h1 class="page-tt">前端开发在线培训视频教程</h1>
<!-- 详细页 -->
<h1 class="page-tt">html5+CSS3</h1>
```
## img设置alt属性
img必须设置alt属性，如果宽度和高度固定请同时设置固定的值
```html
<img src="" alt="seo优化实战" width="200" height="100" />
```
## nofollow
对不需要跟踪爬行的链接，设置nofollow。可用在博客评论、论坛帖子、社会化网站、留言板等地方，也可用于广告链接，还可用于隐私政策，用户条款，登录等。如下代码表示该链接不需要跟踪爬行，可以阻止蜘蛛爬行及传递权重。
```html
<a href="http://example.com" rel="nofollow">no follow 链接</a>
```

## 正文
### 内容方面考虑：
自然写作
高质量原创内容
吸引阅读的写作手法
突出卖点
增强信任感
引导进一步行为
### 用户体验方面考虑：
排版合理、清晰、美观、字体、背景易于阅读
实质内容处在页面最重要位置，用户一眼就能看到
实质内容与广告能够清晰区分
第一屏就有实质内容，而不是需要下拉页面才能看到
广告数量不宜过多，位置不应该妨碍用户阅读
如果图片、视频有利于用户理解页面内容，尽量制作图片、视频等
避免过多弹窗

## URL优化
URL设计原则：

越短越好
避免太多参数
目录层次尽量少
文件及目录名具描述性
URL中包括关键词(中文除外)
字母全部小写
连词符使用-而不是_
目录形式而非文件形式
## URL静态化
以现在搜索引擎的爬行能力是可以不用做静态化的，但是从收录难易度，用户体验及社会化分享，静态简短的URL都是更有利的。
具体讨论可参考：URL静态化还是不静态化？

## URL规范化
### 1、统一连接
```js
http://www.domainname.com
http://domainname.com
http://www.domainname.com/index.html
http://domainname.com/index.html
```
以上四个其实都是首页，虽然不会给访客造成什么麻烦，但对于搜索引擎来说就是四条网址，并且内容相同，很可能会被误认为是作弊手段，而且当搜索引擎要规范化网址时，需要从这些选择当中挑一个最好的代表，但是挑的这个不一定是你想要的。所以最好自己就规范好。

### 2、301跳转
第一种是URL发生改变，一定要把旧的地址301指向新的，不然之前做的一些收录权重什么的全白搭了。
第二种是一些cms系统，极有可能会造成多个路径对应同一篇文章。如drupal默认的路径是以node/nid，但是如果启用了path token，就可以自己自定义路径。这样一来就有两条路径对应同一篇文章。所以可以启用301，最终转向一个路径。

### 3、canonical
这个标签表示页面的唯一性（这个标签以前百度不支持，现在支持），用在平时参数传递的时候，如：
```js
//:ke.qq.com/download/app.html
//:ke.qq.com/download/app.html?from=123
//:ke.qq.com/download/app.html?from=456
``` 
以上三个表示三个页面，但其实后两个只是想表明从哪来的而已，所以为了确保这三个为同一个页面，我们在head上加上canonical标签。
```html
<link rel="cononical" href="//:ke.qq.com/download/download/app.html" />
```

## robots
robots.txt
搜索引擎蜘蛛访问网站时会第一个访问robots.txt文件，robots.txt用于指导搜索引擎蜘蛛禁止抓取网站某些内容或只允许抓取那些内容，放在站点根目录。

1. User-agent 表示以下规则适用哪个蜘蛛，*表示所有
2. `#`表示注释
3. Disallow 表示禁止抓取的文件或目录，必须每个一行，分开写
4. Allow 表示允许抓取的文件或目录，必须每个一行，分开写
5. Sitemap 表示站点XML地图，注意S大写
下面表示禁止所有搜索引擎蜘蛛抓取任何内容
User-agent: *
Disallow: /
下面表示允许所有搜索引擎蜘蛛抓取任何内容
User-agent: *
Disallow:
注意：被robots禁止抓取的URL还是肯呢个被索引并出现在搜索结果中的。只要有导入链接指向这个URL，搜索引擎就知道这个URL的存在，虽然不会抓取页面内容，但是索引库还是有这个URL的信息。以淘宝为例：


## meta robots
如果要想URL完全不出现在搜索结果中，则需设置meta robots
``` html
<meta name="robots" content="onindex,nofollow">
```
上面代码表示：禁止所有搜索引擎索引本页，禁止跟踪本页上的链接。
当然还有其他类型的content，不过各个浏览器支持情况不同，所以这里忽略。
